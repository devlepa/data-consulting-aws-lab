# ğŸ“Š data-consulting-aws-lab

### **End-to-End Data Analytics & Consulting Lab using AWS, Python & Modern Data Architecture**

This project simulates the real work of a **Data Consultant / Data Engineer** inside a mid-sized enterprise struggling with **data silos**.
Your mission is to:

âœ” Ingest & unify disconnected datasets
âœ” Build a consistent enterprise data model
âœ” Generate synthetic data for 5 business domains
âœ” Prepare pipelines for AWS (S3, Glue, Athena)
âœ” Perform analytics, modeling & dashboarding

It is designed as a **real consulting project**, helping you learn the exact workflow used by AWS partners, Deloitte, Accenture, and real enterprise teams.

---

# ğŸ¢ 1. Business Context

The company has **multiple disconnected data sources (â€œsilosâ€)** across the main business areas:

* Finance
* Marketing
* E-commerce
* CRM
* Web Analytics

Your job is to **centralize all this data**, create a **unified analytical model**, and prepare everything for a cloud data platform.

---

# ğŸ§© 2. Project Architecture (Final Structure)

```
data-consulting-aws-lab/
â”‚
â”œâ”€â”€ .venv/                          â† Local Python virtual environment
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                        â† Raw synthetic datasets (bronze layer)
â”‚   â”‚   â”œâ”€â”€ finance/
â”‚   â”‚   â”œâ”€â”€ marketing/
â”‚   â”‚   â”œâ”€â”€ ecommerce/
â”‚   â”‚   â”œâ”€â”€ crm/                    â† future
â”‚   â”‚   â””â”€â”€ web/                    â† future
â”‚   â”‚
â”‚   â”œâ”€â”€ processed/                  â† Cleaned / transformed datasets (silver)
â”‚   â””â”€â”€ docs/                       â† Data dictionaries & domain documentation
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ diagrams/                   â† System diagrams, ERDs, architecture
â”‚   â”œâ”€â”€ domain_definitions.md
â”‚   â”œâ”€â”€ data_dictionary.md
â”‚   â””â”€â”€ architecture.md
â”‚
â”œâ”€â”€ notebooks/                      â† EDA, analytics, experiments
â”‚   â”œâ”€â”€ finance_analysis.ipynb
â”‚   â”œâ”€â”€ marketing_analysis.ipynb
â”‚   â”œâ”€â”€ ecommerce_analysis.ipynb
â”‚   â””â”€â”€ aws_setup.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ etl/                        â† ETL pipelines: synthetic data generators
â”‚   â”‚   â”œâ”€â”€ generate_finance_data.py
â”‚   â”‚   â”œâ”€â”€ generate_marketing_data.py
â”‚   â”‚   â”œâ”€â”€ generate_ecommerce_domain.py
â”‚   â”‚   â”œâ”€â”€ generate_crm_data.py          â† future
â”‚   â”‚   â””â”€â”€ generate_web_analytics.py     â† future
â”‚   â”‚
â”‚   â”œâ”€â”€ analytics/                  â† Business logic, metrics, KPI engines
â”‚   â”‚   â”œâ”€â”€ finance_metrics.py
â”‚   â”‚   â”œâ”€â”€ ecommerce_kpis.py
â”‚   â”‚   â””â”€â”€ marketing_attribution.py
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                     â† ML models: churn, LTV, segmentation
â”‚   â”‚   â”œâ”€â”€ churn_model.py
â”‚   â”‚   â””â”€â”€ product_recommender.py
â”‚   â”‚
â”‚   â””â”€â”€ utils/                      â† Helpers for logging, configs, validations
â”‚       â”œâ”€â”€ logger.py
â”‚       â”œâ”€â”€ file_io.py
â”‚       â””â”€â”€ validation.py
â”‚
â”œâ”€â”€ tests/                          â† Unit tests for ETL and analytics modules
â”‚   â”œâ”€â”€ test_finance_etl.py
â”‚   â”œâ”€â”€ test_marketing_etl.py
â”‚   â””â”€â”€ test_ecommerce_etl.py
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

# ğŸ§± 3. Business Domains & Datasets

The following **five universal enterprise domains** are implemented (or will be):

---

## **Finance Domain**

âœ” Accounting & revenue backbone
âœ” Source of truth for financial transactions

**Datasets**

* orders
* invoices
* payments
* expenses
* vendors
* chart_of_accounts
* gl_transactions

---

## **Marketing Domain**

âœ” Paid media
âœ” Funnels: Lead â†’ MQL â†’ Customer â†’ Buyer
âœ” Ad attribution & spend tracking

**Datasets**

* campaigns
* ad_groups
* ads
* daily_performance
* leads

---

## **E-commerce Domain**

âœ” Online transactions
âœ” Customer behavior
âœ” Product catalog
âœ” Returns & unit economics

**Datasets**

* products
* customers
* orders (linked to Finance)
* order_items
* returns

---

## **CRM Domain** *(upcoming)*

âœ” Customer 360Â°
âœ” Segmentation
âœ” Interactions & support tickets
âœ” Churn predictions

---

## **Web Analytics Domain** *(upcoming)*

âœ” User behavior
âœ” Digital funnels
âœ” Traffic sources
âœ” Pageview tracking

---

# ğŸ“˜ 4. Key Consulting & Data Terms (learn these)

These terms are used daily in data engineering, analytics consulting, and AWS workflows:

| Term                 | Meaning                                    |
| -------------------- | ------------------------------------------ |
| **Domain**           | A business area (Finance, Marketing, CRM)  |
| **Entity**           | Logical dataset (Customer, Order, Product) |
| **Silo**             | Data stored in isolation                   |
| **Attribute**        | Column of a dataset                        |
| **Primary Key (PK)** | Unique identifier                          |
| **Foreign Key (FK)** | Reference to another table                 |
| **Fact Table**       | Stores events: orders, payments, clicks    |
| **Dimension Table**  | Stores context: customers, dates           |
| **Star Schema**      | Fact in the center, dimensions around      |
| **Synthetic Data**   | Realistic fake data for learning/testing   |

---

# ğŸš€ 5. Git Workflow (Professional Branching Strategy)

This repo uses a **consulting-standard Git Flow**:

```
main        â†’ stable production code  
test        â†’ integration & QA environment  
feature/*   â†’ active development branches
```

Workflow:

```
feature â†’ test â†’ main
```

No direct pushes to main.

---

# ğŸŒ©ï¸ 6. AWS Implementation Roadmap

This project is designed to migrate into a cloud-native AWS pipeline:

### **1. AWS S3 (Data Lake)**

* Raw (bronze)
* Cleaned (silver)
* Curated (gold)

### **2. AWS Glue**

* Crawlers (schema discovery)
* ETL (PySpark jobs)
* Catalog (Hive Metastore)

### **3. AWS Athena**

* Query the data lake
* Build star schemas
* Prepare analytics tables

### **4. Amazon QuickSight**

* Dashboards:

  * Finance
  * Marketing
  * E-commerce
  * Customer 360Â°

### **5. Optional ML**

* Churn prediction
* Segmentation
* Marketing attribution models
* Demand forecasting

---

# ğŸ”§ 7. How to Run Local ETL

Activate your environment:

```bash
source .venv/Scripts/activate
```

Generate each domain:

```bash
python src/etl/generate_finance_data.py
python src/etl/generate_marketing_data.py
python src/etl/generate_ecommerce_domain.py
```

Outputs are saved into:

```
data/raw/<domain>/
```

---

# ğŸ“ˆ 8. Purpose of This Lab

This project helps you build skills in:

âœ” Data engineering
âœ” Analytics consulting
âœ” Enterprise data modeling
âœ” ETL pipelines
âœ” AWS data lake architecture
âœ” BI & SQL analysis
âœ” ML pipeline integration


# ğŸ™Œ Author

**Juan Leon**
Data Engineer â€¢ AI & Computing Science Student â€¢ AWS + Python Practitioner


